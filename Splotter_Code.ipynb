{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, make sure you have these packages:**\n",
    "- numpy\n",
    "- pandas\n",
    "- matplotlib\n",
    "- astropy\n",
    "- linetools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, run the cell below and go to the last cell in this notebook under 'Example Code' and adjust the variables.**\n",
    "\n",
    "**Make sure you have the files I sent on Slack downloaded to the directory you are working in.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splotter(high, low1, low2, user_dir, spectra_dir, all_csv, galaxy_csv, diff_tol=40):\n",
    "    '''\n",
    "    Inputs:\n",
    "    high: string containing name of high-ion (needs to match transition name in all_df dataframe)\n",
    "    low1: string containing name of first low-ion (needs to match transition name in all_df dataframe)\n",
    "    low2: string containing name of second low-ion (needs to match transition name in all_df dataframe)\n",
    "    all_csv: csv containing including any high-ion and low-ions to be aligned in stack plots\n",
    "    galaxy_csv: csv containing all galaxies. Any ions specified as high, low1 or low2 within 500km/s will be included in stack plots\n",
    "    user_dir: string containing directory in which the user wish to save stack plots\n",
    "    spectra_dir: string containing directory where the analyzed spectra (.fits files) for each sightline is located\n",
    "    diff_tol: float that determines within what central velocity difference a line is not considered no-low (in km/s) (default is 40)\n",
    "    \n",
    "    Outputs:\n",
    "    Saves pdfs (stack plots) for all alignments within the high-ion and low-ion dataframe\n",
    "    These pdfs are saved in a directory named identically after the high-ion input string and in organized subdirectories categorized as \"stack_plots\", \"stack_plots_data\" and \"stats\"\n",
    "    Both \"stack_plots\" and \"stack_plots_data\" have subdirectories \"no-lows\", \"narrows\" and \"broads\" corresponding to the identified alignment categories and all a copy of these plots are also saved to the \"all_alignments\" subdirectory\n",
    "    Each plot/pdf that is saved to \"stack_plots\" has a corresponding .csv file which contains important data about each ion and the nearby galaxy and are saved to the subdirectory \"stack_plots_data\"\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Importing necessary libraries:\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    import glob\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from astropy.io import fits\n",
    "    from astropy.table import Table\n",
    "\n",
    "    from astropy import units as u\n",
    "    from astropy import constants as const\n",
    "    # New definition\n",
    "    c_in_km_per_s = const.c.to('km/s').value\n",
    "    \n",
    "    from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "    \n",
    "    from linetools.spectralline import AbsLine\n",
    "    from linetools.isgm import utils as ltiu\n",
    "    from linetools.analysis import absline as laa\n",
    "    from linetools.spectra import io as lsio\n",
    "    from linetools.isgm.abscomponent import AbsComponent\n",
    "    from linetools.spectra.xspectrum1d import XSpectrum1D\n",
    "\n",
    "    import imp\n",
    "    lt_path = imp.find_module('linetools')[1]\n",
    "\n",
    "    from linetools.analysis import voigt as lav\n",
    "\n",
    "    #new imports\n",
    "    from linetools.lists.linelist import LineList\n",
    "    from linetools.analysis.plots import stack_plot\n",
    "\n",
    "\n",
    "    ISM_linelist = LineList('ISM')\n",
    "    plt.style.use('fast')\n",
    "    \n",
    "    \n",
    "    # Defining preliminary functions:\n",
    "    \n",
    "    def make_absline(df_row):\n",
    "        restwave = df_row.restwave*u.AA\n",
    "        z_absorber = (1 + df_row.zsys)*(1 + df_row.vel/c_in_km_per_s) - 1\n",
    "        attribs = {\n",
    "            'b': df_row.bval * u.km/u.s,\n",
    "            'logN': df_row.col,\n",
    "            'QSO': df_row.QSO,\n",
    "            'N':10**df_row.col / u.cm**2,\n",
    "            'vel': df_row.vel * u.km/u.s,\n",
    "            'z_abs': z_absorber,\n",
    "            'z_gal': df_row.z_gal,\n",
    "            'trans': df_row.trans\n",
    "                  } \n",
    "        #lav.voigt_from_abslines wants the column density info to be in the `'N'` attrib, doesn't check `'logN'`\n",
    "\n",
    "        #pass in a linelist so `linetools` doesn't load one every time this method is called\n",
    "        absline = AbsLine(restwave, z=z_absorber, linelist=ISM_linelist)\n",
    "        for name, value in attribs.items():\n",
    "            absline.attrib[name] = value\n",
    "\n",
    "        return absline\n",
    "    \n",
    "    def splotter_plotter(high, low1, low2, lines, aligned_df, galaxy_df, qso, z_high, keyword, user_dir, spectra_dir): #subdir takes an array of strings\n",
    "        if keyword == \"no-low\":\n",
    "            subdirs = ['/no-lows', '/all_alignments']\n",
    "        elif keyword == \"narrow\":\n",
    "            subdirs = ['/narrows', '/all_alignments']\n",
    "        elif keyword == \"broad\":\n",
    "            subdirs = ['/broads', '/all_alignments']\n",
    "        else:\n",
    "            print('INVALID KEYWORD')\n",
    "\n",
    "\n",
    "        for index in range(0, len(subdirs)):\n",
    "            #`indices` are all associated with the same QSO and the system\n",
    "            z_galaxy = z_high\n",
    "            sightline = qso #line.attrib['QSO']\n",
    "            xspec = lsio.readspec(f'{spectra_dir}{sightline}_nbin3_norm.fits')\n",
    "\n",
    "            for line in lines:\n",
    "                line.analy['spec'] = xspec # Start plotting\n",
    "\n",
    "            #synthesize and assign model voigt profiles\n",
    "            wv_array = xspec.wavelength\n",
    "            all_voigts = lav.voigt_from_abslines(wv_array, lines, fwhm=None, \n",
    "                                         ret=['flux'], debug=False)\n",
    "\n",
    "            #all_voigts.sig = np.full([len(wv_array)], 0)\n",
    "            xspec.sig = all_voigts * xspec.co\n",
    "\n",
    "            fig = stack_plot(lines, zref=z_galaxy, vlim=[-750, 750]*u.km/u.s, return_fig=True)\n",
    "\n",
    "            # Adding text to plot\n",
    "            for i in range(0, len(lines)):\n",
    "                vel_gal = c_in_km_per_s * ((1+lines[i].attrib[\"z_abs\"])/(1+lines[i].attrib[\"z_gal\"]) - 1)\n",
    "                xticks_list = np.arange(-700, 800, 100)\n",
    "                fig.axes[i].axvline(x=vel_gal, color='r', linestyle='--', linewidth=2)\n",
    "                fig.axes[i].axhline(y=0, color='k', linestyle=(0, (1, 10)), linewidth=0.8)\n",
    "                fig.axes[i].axhline(y=1, color='k', linestyle=(0, (1, 10)), linewidth=0.8)\n",
    "                fig.axes[i].set_xticks(xticks_list)\n",
    "                if len(lines) == 2:\n",
    "                    fig.axes[i].text(-600, 0.24, \"bval={:.4f}\".format(lines[i].attrib[\"b\"]))\n",
    "                    fig.axes[i].text(-600, 0.17, \"col={:.4f}\".format(lines[i].attrib[\"logN\"]))\n",
    "                    fig.axes[i].text(-600, 0.1, \"vel_gal={:.4f}\".format(vel_gal))\n",
    "                    fig.axes[i].text(600, 0.1, \"z_abs={:.5f}\".format(lines[i].attrib[\"z_abs\"]))\n",
    "                elif len(lines) == 3:\n",
    "                    fig.axes[i].text(-600, 0.3, \"bval={:.4f}\".format(lines[i].attrib[\"b\"]))\n",
    "                    fig.axes[i].text(-600, 0.2, \"col={:.4f}\".format(lines[i].attrib[\"logN\"]))\n",
    "                    fig.axes[i].text(-600, 0.1, \"vel_gal={:.4f}\".format(vel_gal))\n",
    "                    fig.axes[i].text(600, 0.1, \"z_abs={:.5f}\".format(lines[i].attrib[\"z_abs\"]))\n",
    "                elif len(lines) == 4:\n",
    "                    fig.axes[i].text(-600, 0.38, \"bval={:.4f}\".format(lines[i].attrib[\"b\"]))\n",
    "                    fig.axes[i].text(-600, 0.26, \"col={:.4f}\".format(lines[i].attrib[\"logN\"]))\n",
    "                    fig.axes[i].text(-600, 0.14, \"vel_gal={:.4f}\".format(vel_gal))\n",
    "                    fig.axes[i].text(600, 0.14, \"z_abs={:.5f}\".format(lines[i].attrib[\"z_abs\"]))\n",
    "                elif len(lines) == 5:\n",
    "                    fig.axes[i].text(-600, 0.44, \"bval={:.4f}\".format(lines[i].attrib[\"b\"]))\n",
    "                    fig.axes[i].text(-600, 0.32, \"col={:.4f}\".format(lines[i].attrib[\"logN\"]))\n",
    "                    fig.axes[i].text(-600, 0.2, \"vel_gal={:.4f}\".format(vel_gal))\n",
    "                    fig.axes[i].text(600, 0.2, \"z_abs={:.5f}\".format(lines[i].attrib[\"z_abs\"]))\n",
    "                else:\n",
    "                    fig.axes[i].text(-600, 0.5, \"bval={:.4f}\".format(lines[i].attrib[\"b\"]))\n",
    "                    fig.axes[i].text(-600, 0.35, \"col={:.4f}\".format(lines[i].attrib[\"logN\"]))\n",
    "                    fig.axes[i].text(-600, 0.2, \"vel_gal={:.4f}\".format(vel_gal))\n",
    "                    fig.axes[i].text(450, 0.1, \"z_abs={:.5f}\".format(lines[i].attrib[\"z_abs\"]))\n",
    "            ion_string = ''\n",
    "            if aligned_df.trans.str.contains(low1).any() and aligned_df.trans.str.contains(low2).any():\n",
    "                ion_string = f\"{low1} and {low2}\"\n",
    "            elif aligned_df.trans.str.contains(low1).any():\n",
    "                ion_string = low1\n",
    "            elif aligned_df.trans.str.contains(low2).any():\n",
    "                ion_string = low2\n",
    "\n",
    "            if ion_string == '':\n",
    "                string = f'{high} has no low-ion within range'\n",
    "            else:\n",
    "                string = f'{high} has low-ion(s) within range: '\n",
    "            galaxy_row = galaxy_df.loc[galaxy_df[\"OBJECT\"]==qso].loc[round(galaxy_df[\"z\"], 7)==round(z_galaxy, 7)] # Make sure galaxy's redshift has same number of decimals included as z_galaxy\n",
    "            rho_impact = galaxy_row.iloc[0][\"rho_impact\"]\n",
    "            rho_rvir = galaxy_row.iloc[0][\"rho_rvir\"]\n",
    "            mstars = galaxy_row.iloc[0][\"mstars\"]\n",
    "            gal_type = galaxy_row.iloc[0][\"gal_type\"]\n",
    "\n",
    "            title_type = ''\n",
    "            if '/no-lows' in subdirs:\n",
    "                title_type = 'No-Low'\n",
    "            elif '/broads' in subdirs:\n",
    "                title_type = 'Broad'\n",
    "            elif '/narrows' in subdirs:\n",
    "                title_type = 'Narrow'\n",
    "            if len(lines) in (2, 3, 4, 5, 6):\n",
    "                titlesize = 20\n",
    "            else:\n",
    "                titlesize = 14\n",
    "            fig.axes[0].set_title(f'{string}{ion_string}  |  {title_type}\\nQSO: {sightline}  |  z_gal={z_galaxy:.5f}  |  rho_impact={rho_impact:.4f}  |  rho_rvir={rho_rvir:.4f}  |  mstars={mstars:.2f}  |  gal_type={gal_type}', fontweight = 'bold', fontsize = titlesize, pad = 20)\n",
    "\n",
    "            # Saving to pdf\n",
    "            filename = f'{user_dir}stack_plots{subdirs[index]}/{sightline}_{z_galaxy:.5f}_stack_plot.pdf'\n",
    "            fig.savefig(filename)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "            # Saving stack plot data to csv\n",
    "            z_gal_list = []\n",
    "            z_abs_list = []\n",
    "            vel_gal_list = []\n",
    "            bval_list = []\n",
    "            col_list = []\n",
    "            transition_list = []\n",
    "            for i in range(0, len(lines)):\n",
    "                z_gal_list.append(lines[i].attrib[\"z_gal\"])\n",
    "                z_abs_list.append(lines[i].attrib[\"z_abs\"])\n",
    "                vel_gal = c_in_km_per_s * ((1+lines[i].attrib[\"z_abs\"])/(1+lines[i].attrib[\"z_gal\"]) - 1)\n",
    "                vel_gal_list.append(vel_gal)\n",
    "                bval_list.append(lines[i].attrib[\"b\"])\n",
    "                col_list.append(lines[i].attrib[\"logN\"])\n",
    "                transition_list.append(lines[i].attrib[\"trans\"])\n",
    "            alignment_type = ''\n",
    "            if '/no-lows' in subdirs:\n",
    "                alignment_type = 'No-Low'\n",
    "            elif '/broads' in subdirs:\n",
    "                alignment_type = 'Broad'\n",
    "            elif '/narrows' in subdirs:\n",
    "                alignment_type = 'Narrow'\n",
    "            else:\n",
    "                alignment_type = ''\n",
    "            dat = {\"filename\" : filename, \"QSO\" : qso, \"z_gal\" : z_gal_list, \"rho_impact\" : rho_impact, \"rho_rvir\" : rho_rvir, \"mstars\" : mstars, \"gal_type\" : gal_type, \"z_abs\" : z_abs_list, \"vel_gal\" : vel_gal_list, \"bval\" : bval_list, \"col\" : col_list, \"alignment_type\" : alignment_type, \"trans\" : transition_list}\n",
    "            stackplot_df = pd.DataFrame(data = dat)\n",
    "            stackplot_df.to_csv(f'{user_dir}stack_plots_data/all_stack_plots{subdirs[index]}/{sightline}_{z_galaxy:.5f}_stack_plot_data.csv', sep=',')\n",
    "    \n",
    "    \n",
    "    # Creating directories:\n",
    "    directory = high\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        print(f'\\nCreated directory {directory}.\\n')\n",
    "    else:\n",
    "        print(f'\\n{directory} directory already exists. Overwriting existing {directory} directory.\\n')\n",
    "    \n",
    "    user_dir = user_dir + high + '/' # Change in user_dir!\n",
    "    \n",
    "    directory = 'stack_plots'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots_data'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots_data/all_stack_plots'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stats'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    directory = 'stack_plots/all_alignments'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots/no-lows'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots/narrows'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots/broads'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "#     directory = 'stack_plots/no-lows_strict'\n",
    "#     path = os.path.join(user_dir, directory)\n",
    "#     if not os.path.exists(path):\n",
    "#         os.mkdir(path)\n",
    "    \n",
    "    directory = 'stack_plots_data/all_stack_plots/all_alignments'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots_data/all_stack_plots/no-lows'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots_data/all_stack_plots/narrows'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    directory = 'stack_plots_data/all_stack_plots/broads'\n",
    "    path = os.path.join(user_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    \n",
    "    # Preparing dataframe containing all high and low-ion transitions from finished all_csv that are within 500km/s of any galaxies in the galaxy_csv\n",
    "    print(f'Identifying absorbers within 500km/s of galaxies...')\n",
    "    galaxy_df = pd.read_csv(f'{galaxy_csv}', sep=',')\n",
    "    all_df = pd.read_csv(f'{all_csv}', sep=',')\n",
    "    all_df = all_df.sort_values(['QSO', 'z_comp'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "    vel_diff = 500\n",
    "    # Criteria specific to H I high-ion:\n",
    "    if high == 'H I':\n",
    "        highall_df = all_df[all_df[\"trans\"] == high]\n",
    "        high_df = pd.DataFrame()\n",
    "        for index, row in galaxy_df.iterrows():\n",
    "            rho_impact_gal = row[\"rho_impact\"]\n",
    "            if rho_impact_gal <= 500: # rho_impact <= 500 kpc\n",
    "                z_gal = row[\"z\"]\n",
    "                qso_gal = row[\"OBJECT\"]\n",
    "                for index, row in highall_df.iterrows():\n",
    "                    col_abs = row[\"col\"]\n",
    "                    if col_abs > 14: # Hcol > 10^14\n",
    "                        z_abs = row[\"zsys\"]\n",
    "                        qso_abs = row[\"QSO\"]\n",
    "                        z_diff = vel_diff*(1+z_gal)/c_in_km_per_s\n",
    "                        if ((z_gal-z_diff) < z_abs < (z_gal+z_diff)) and (qso_abs == qso_gal):\n",
    "                            row[\"z_gal\"] = z_gal\n",
    "                            high_df = high_df.append(row, ignore_index=True)\n",
    "    # All other high-ions:\n",
    "    else:\n",
    "        highall_df = all_df[all_df[\"trans\"] == high]\n",
    "        high_df = pd.DataFrame()\n",
    "        for index, row in galaxy_df.iterrows():\n",
    "            z_gal = row[\"z\"]\n",
    "            qso_gal = row[\"OBJECT\"]\n",
    "            for index, row in highall_df.iterrows():\n",
    "                z_abs = row[\"zsys\"]\n",
    "                qso_abs = row[\"QSO\"]\n",
    "                z_diff = vel_diff*(1+z_gal)/c_in_km_per_s\n",
    "                if ((z_gal-z_diff) < z_abs < (z_gal+z_diff)) and (qso_abs == qso_gal):\n",
    "                    row[\"z_gal\"] = z_gal\n",
    "                    high_df = high_df.append(row, ignore_index=True)\n",
    "\n",
    "    low1all_df = all_df[all_df[\"trans\"] == low1]\n",
    "    low1_df = pd.DataFrame()\n",
    "    for index, row in galaxy_df.iterrows():\n",
    "        z_gal = row[\"z\"]\n",
    "        qso_gal = row[\"OBJECT\"]\n",
    "        for index, row in low1all_df.iterrows():\n",
    "            z_abs = row[\"zsys\"]\n",
    "            qso_abs = row[\"QSO\"]\n",
    "            z_diff = vel_diff*(1+z_gal)/c_in_km_per_s\n",
    "            if ((z_gal-z_diff) < z_abs < (z_gal+z_diff)) and (qso_abs == qso_gal):\n",
    "                row[\"z_gal\"] = z_gal\n",
    "                low1_df = low1_df.append(row, ignore_index=True)\n",
    "                \n",
    "    low2all_df = all_df[all_df[\"trans\"] == low2]\n",
    "    low2_df = pd.DataFrame()\n",
    "    for index, row in galaxy_df.iterrows():\n",
    "        z_gal = row[\"z\"]\n",
    "        qso_gal = row[\"OBJECT\"]\n",
    "        for index, row in low2all_df.iterrows():\n",
    "            z_abs = row[\"zsys\"]\n",
    "            qso_abs = row[\"QSO\"]\n",
    "            z_diff = vel_diff*(1+z_gal)/c_in_km_per_s\n",
    "            if ((z_gal-z_diff) < z_abs < (z_gal+z_diff)) and (qso_abs == qso_gal):\n",
    "                row[\"z_gal\"] = z_gal\n",
    "                low2_df = low2_df.append(row, ignore_index=True)\n",
    "                \n",
    "    dfs = [high_df, low1_df, low2_df]\n",
    "    abs_df = pd.concat(dfs)\n",
    "    abs_df = (\n",
    "    abs_df\n",
    "    .set_index([\"QSO\", \"z_gal\"])\n",
    "    .sort_values([\"QSO\", \"z_gal\"], ascending=True)\n",
    "    )\n",
    "    print('Completed.\\n')\n",
    "          \n",
    "    # Finding alignments:\n",
    "    # Creating dataframe with all relevant ions in the qso\n",
    "    print('Finding alignments and creating stack plots...')\n",
    "    for qso, qso_df in abs_df.groupby(level=0):\n",
    "        print(qso)\n",
    "        if qso_df.trans.str.contains(high).any():\n",
    "            high_df = (\n",
    "                qso_df\n",
    "                .query(f'trans == \"%s\"' % high)\n",
    "                .sort_values(\"z_gal\")\n",
    "            )\n",
    "            low1_df = (\n",
    "                qso_df\n",
    "                .query(f'trans == \"%s\"' % low1)\n",
    "                .sort_values(\"z_gal\")\n",
    "            )\n",
    "            low2_df = (\n",
    "                qso_df\n",
    "                .query(f'trans == \"%s\"' % low2)\n",
    "                .sort_values(\"z_gal\")\n",
    "            )\n",
    "\n",
    "\n",
    "            # Identifying all alignments between OVI and the low ions\n",
    "            for z_high, z_highdf in high_df.groupby(level=1):\n",
    "                #if math.floor(z_Odf.restwave[0]) == 1031: # Only plotting if OVI is 1031 and not 1037. This way we avoid printing two of the same plot\n",
    "                #if z_highdf.index[0][1] == z_highdf.index[1][1]:\n",
    "                aligned_df = pd.DataFrame()\n",
    "                z_highdf[\"z_gal\"] = z_high\n",
    "                aligned_df = aligned_df.append(z_highdf)\n",
    "                print(f'{high} {z_high}')\n",
    "\n",
    "                if low1_df.index.size != 0:\n",
    "                    for z_low1, z_low1df in low1_df.groupby(level=1):\n",
    "                        if z_low1 == z_high:\n",
    "                            z_low1df[\"z_gal\"] = z_low1\n",
    "                            aligned_df = aligned_df.append(z_low1df)\n",
    "                            print(f'{low1} {z_low1}')\n",
    "\n",
    "                if low2_df.index.size != 0:\n",
    "                    for z_low2, z_low2df in low2_df.groupby(level=1):\n",
    "                        if z_low2 == z_high:\n",
    "                            z_low2df[\"z_gal\"] = z_low2\n",
    "                            aligned_df = aligned_df.append(z_low2df)\n",
    "                            print(f'{low2} {z_low2}')\n",
    "\n",
    "\n",
    "# No-Low:\n",
    "                if (aligned_df.index.size != 0) and (aligned_df.trans.str.contains(low1).any() or aligned_df.trans.str.contains(low2).any()):\n",
    "                    lines = []\n",
    "                    indices = np.arange(0, aligned_df.index.size)\n",
    "                    for ind in indices:\n",
    "                        absline_df = aligned_df.iloc[ind]\n",
    "                        absline_df[\"QSO\"] = qso\n",
    "                        line = make_absline(absline_df)\n",
    "                        lines.append(line)\n",
    "                    highvel_list = []\n",
    "                    othervel_list = []\n",
    "                    for line in lines:\n",
    "                        if line.attrib['trans'] == high:\n",
    "                            vel_gal = c_in_km_per_s * ((1+line.attrib[\"z_abs\"])/(1+line.attrib[\"z_gal\"]) - 1)\n",
    "                            highvel_list.append(vel_gal)\n",
    "                        else:\n",
    "                            vel_gal = c_in_km_per_s * ((1+line.attrib[\"z_abs\"])/(1+line.attrib[\"z_gal\"]) - 1)\n",
    "                            othervel_list.append(vel_gal)\n",
    "                    vel_diffs = []\n",
    "                    for i in range(0, len(highvel_list)):\n",
    "                        for j in range(0, len(othervel_list)):\n",
    "                            diff = highvel_list[i] - othervel_list[j]\n",
    "                            diff = abs(diff)\n",
    "                            vel_diffs.append(diff)\n",
    "                    min_diff = min(vel_diffs)\n",
    "\n",
    "                    if (min_diff > diff_tol) and not ((high == \"O VI\") and (qso == 'J1241+5721') and ((round(z_high, 3) == 0.147) or (round(z_high, 5) == 0.14650))):\n",
    "                        keyword = \"no-low\"\n",
    "                        splotter_plotter(high, low1, low2, lines, aligned_df, galaxy_df, qso, z_high, keyword, user_dir, spectra_dir)\n",
    "# Broad/Narrow:\n",
    "                    else:\n",
    "                        b_vals = [] # Contains bvals for OVI\n",
    "                        for line in lines:\n",
    "                            if line.attrib['trans'] == high:\n",
    "                                b_val = line.attrib[\"b\"]\n",
    "                                b_vals.append(b_val)\n",
    "                        max_bval = max(b_vals)\n",
    "# Broad:\n",
    "                        if max_bval > 40*u.km/u.s:\n",
    "                            keyword = \"broad\"\n",
    "                            splotter_plotter(high, low1, low2, lines, aligned_df, galaxy_df, qso, z_high, keyword, user_dir, spectra_dir)\n",
    "# Narrow:\n",
    "                        else:\n",
    "                            keyword = \"narrow\"\n",
    "                            splotter_plotter(high, low1, low2, lines, aligned_df, galaxy_df, qso, z_high, keyword, user_dir, spectra_dir)\n",
    "\n",
    "# No-Low (2nd sequence):\n",
    "                elif (aligned_df.index.size != 0) and not (aligned_df.trans.str.contains(low1).any() or aligned_df.trans.str.contains(low2).any()):\n",
    "                    lines = []\n",
    "                    indices = np.arange(0, aligned_df.index.size)\n",
    "                    for ind in indices:\n",
    "                        absline_df = aligned_df.iloc[ind]\n",
    "                        absline_df[\"QSO\"] = qso\n",
    "                        line = make_absline(absline_df)\n",
    "                        lines.append(line)\n",
    "\n",
    "                    keyword = \"no-low\"\n",
    "                    splotter_plotter(high, low1, low2, lines, aligned_df, galaxy_df, qso, z_high, keyword, user_dir, spectra_dir)\n",
    "\n",
    "    # Saving stats:\n",
    "    all_dir = f'{user_dir}stack_plots/all_alignments'\n",
    "    nolow_dir = f'{user_dir}stack_plots/no-lows'\n",
    "    broad_dir = f'{user_dir}stack_plots/broads'\n",
    "    narrow_dir = f'{user_dir}stack_plots/narrows'\n",
    "\n",
    "    all_list = glob.glob(all_dir + '/*')\n",
    "    nolow_list = glob.glob(nolow_dir + '/*')\n",
    "    broad_list = glob.glob(broad_dir + '/*')\n",
    "    narrow_list = glob.glob(narrow_dir + '/*')\n",
    "\n",
    "    all_num = len(all_list)\n",
    "    nolow_num = len(nolow_list)\n",
    "    broad_num = len(broad_list)\n",
    "    narrow_num = len(narrow_list)\n",
    "\n",
    "    nolow_frac = nolow_num/all_num\n",
    "    broad_frac = broad_num/all_num\n",
    "    narrow_frac = narrow_num/all_num\n",
    "\n",
    "    # Plotting stats        \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.style.use('fast')\n",
    "    fig.set_size_inches(8,6)\n",
    "    fig.tight_layout(w_pad = 5.0)\n",
    "    ax.bar([1, 2, 3], [broad_num, narrow_num, nolow_num], tick_label = ['Broads', 'Narrows', 'No-Lows'],\n",
    "            width = 0.8, color = ['tab:blue', 'tab:green', 'tab:red'])\n",
    "    ax.set_xlabel('Alignment type', fontweight='bold', fontsize='15')\n",
    "    ax.set_ylabel('Number of alignments', fontweight='bold', fontsize='15')\n",
    "    ax.set_title(f'Kinematic Alignment Stats | High: {high}  Low: {low1}, {low2}', fontweight='bold', fontsize='20')\n",
    "    ax.grid(linestyle='--')\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.yaxis.grid(True, which='minor', linestyle='--', linewidth = 0.2, color='gray')\n",
    "    ax.yaxis.grid(True, which='major', linestyle='-', linewidth = 0.5, color='k')\n",
    "    if max([nolow_num, broad_num, narrow_num]) < 80:\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(5))\n",
    "    ax.yaxis.set_major_formatter('{x:.0f}')\n",
    "    ax.text(0.05, 0.95, f'Broad: {broad_num} ({broad_frac*100:.2f}%)\\nNarrow: {narrow_num} ({narrow_frac*100:.2f}%)\\nNo-Low: {nolow_num} ({nolow_frac*100:.2f}%)\\nTotal: {all_num}', transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "\n",
    "    fig.savefig(f'{user_dir}stats/alignment_stats.pdf', bbox_inches='tight')\n",
    "    \n",
    "    # Printing message:\n",
    "    print(f\"\\n\\nSuccessfully created stack plots for all matching high- and low-ion pairs in the directory \\n\"\n",
    "          f\"{user_dir}stack_plots/\\n\"\n",
    "          f\"Stack plot data can be found in the directory {user_dir}stack_plots_data/ \\n\\n\"\n",
    "          f\"Splotter found {all_num} alignments in total whereas there are {broad_num} broads, {narrow_num} narrows, and {nolow_num} no-lows.\\n\\n\"\n",
    "          f\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_sets: Using set file -- \n",
      "  /Users/eriksolhaug/linetools/linetools/lists/sets/llist_v1.3.ascii\n",
      "Loading abundances from Asplund2009\n",
      "Abundances are relative by number on a logarithmic scale with H=12\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/user_dir/O VI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f6ce5cdf905d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O VI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SiIII\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C III\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/path/to/user_dir/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/path/to/spectra/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/path/to/all_vp.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/path/to/galaxy_data_es.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# INSTRUCTIONS:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Leave \"O VI\", \"SiIII\" and \"C III\" as they are.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e27710a079f7>\u001b[0m in \u001b[0;36msplotter\u001b[0;34m(high, low1, low2, user_dir, spectra_dir, all_csv, galaxy_csv, diff_tol)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nCreated directory {directory}.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/user_dir/O VI'"
     ]
    }
   ],
   "source": [
    "splotter(\"O VI\", \"SiIII\", \"C III\", '/path/to/user_dir/', '/path/to/spectra/', '/path/to/all_vp.csv', '/path/to/galaxy_data_es.csv')\n",
    "# INSTRUCTIONS:\n",
    "\n",
    "# Leave \"O VI\", \"SiIII\" and \"C III\" as they are.\n",
    "\n",
    "# Change the /path/to/ variables to match your directory:\n",
    "# On my computer,\n",
    "# '/path/to/user_dir/' looks like:\n",
    "# '/Users/eriksolhaug/Dropbox/CGM2/Analysis/ErikSAnalysis/'\n",
    "\n",
    "# '/path/to/spectra/' looks like:\n",
    "# '/Users/eriksolhaug/Dropbox/CGM2/Analysis/ErikSAnalysis/spectra/'\n",
    "\n",
    "# '/path/to/all_vp.csv' looks like:\n",
    "# '/Users/eriksolhaug/Dropbox/CGM2/Analysis/ErikSAnalysis/finished_csv/all_vp.csv'\n",
    "# NOTE: This one is not a directory but a file name!\n",
    "\n",
    "# '/path/to/galaxy_data_es.csv' looks like:\n",
    "# '/Users/eriksolhaug/Dropbox/CGM2/Analysis/ErikSAnalysis/data/galaxy_data_es.csv'\n",
    "# NOTE: This one is not a directory but a file name!\n",
    "\n",
    "# You can definitely set all the directory paths equal to the user directory path (likely where you placed this notebook) if this is easier!\n",
    "\n",
    "# If the code runs successfully, then you should see a new subdirectory 'O VI' appear in your user directory ('user_dir')\n",
    "# and the 'O VI' subdirectory should have a bunch of new pdf and csv files in them.\n",
    "# The pdfs are 'stack plots' showing alignment between absorbers in the QSOs we are studying!! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
